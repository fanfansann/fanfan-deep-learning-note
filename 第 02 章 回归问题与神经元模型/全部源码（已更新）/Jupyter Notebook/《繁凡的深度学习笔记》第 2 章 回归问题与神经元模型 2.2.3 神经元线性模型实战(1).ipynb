{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a665c09",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在理解了神经元线性模型的原理以及各种优化算法以后，我们来实战训练单输入神经元线性模型。\n",
    "\n",
    "&emsp;&emsp;首先我们引入需要的包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498ca646",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "# cal y = 1.477x + 0.089 + epsilon,epsilon ~ N(0, 0.01^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e390add",
   "metadata": {},
   "source": [
    "**1. 生成数据集**\n",
    "\n",
    "&emsp;&emsp;我们需要采样自真实模型的多组数据，对于已知真实模型的 **玩具样例** (Toy Example)，我们直接从指定的 $w = 1.477 , b = 0.089$ 的真实模型中直接采样：\n",
    "$$\n",
    "y=1.477 \\times x+0.089\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "&emsp;&emsp;为了能够很好地模拟真实样本的观测误差，我们给模型添加误差自变量 $\\epsilon$ ，它采样自均值为 $0$ ，方差为 $0.01$ 的高斯分布：\n",
    "$$\n",
    "y=1.477 x+0.089+\\epsilon, \\epsilon \\sim \\mathcal{N}(0,0.01)\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;我们通过随机采样 $n = 100$ 次，我们获得 $n$ 个样本的训练数据集 $\\mathbb D_{\\mathrm{train}}$ ，然后循环进行 $100$ 次采样，每次从均匀分布 $U ( -10,10)$ 中随机采样一个数据 $x$ 同时从均值为 $0$ ，方差为 $0.1^{2}$ 的高斯分布 $\\mathcal{N}\\left(0,0.1^{2}\\right)$ 中随机采样噪声 $\\epsilon$，根据真实模型生成 $y$ 的数据，并保存为 $\\text{Numpy}$ 数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbabdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    # 计算均方误差\n",
    "    #保存样本集的列表\n",
    "    data = [] \n",
    "    for i in range(100):\n",
    "        x = np.random.uniform(-10., 10.)  # 随机采样 x\n",
    "        # 高斯噪声\n",
    "        eps = np.random.normal(0., 0.01) # 均值和方差\n",
    "        # 得到模型的输出\n",
    "        y = 1.477 * x + 0.089 + eps\n",
    "        # 保存样本点\n",
    "        data.append([x, y]) \n",
    "    # 转换为2D Numpy数组\n",
    "    data = np.array(data)  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8343d",
   "metadata": {},
   "source": [
    "**2. 计算误差**\n",
    "\n",
    "&emsp;&emsp;循环计算在每个点 $\\left(x^{(i)}, y^{(i)}\\right)$ 处的预测值与真实值之间差的平方并累加，从而获得训练集上的均方差损失值。\n",
    "\n",
    "&emsp;&emsp;最后的误差和除以数据样本总数，从而得到每个样本上的平均误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d85924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(b, w, points) :\n",
    "    totalError = 0\n",
    "    # 根据当前的w，b参数计算均方差损失\n",
    "    for i in range(0, len(points)) : # 循环迭代所有点\n",
    "        # 获得 i 号点的输入 x\n",
    "        x = points[i, 0]\n",
    "        # 获得 i 号点的输出 y\n",
    "        y = points[i, 1]\n",
    "        # 计算差的平方，并累加\n",
    "        totalError += (y - (w * x + b)) ** 2\n",
    "    # 将累加的误差求平均，得到均方误差\n",
    "    return totalError / float(len(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953d873",
   "metadata": {},
   "source": [
    "**3. 计算梯度**\n",
    "\n",
    "&emsp;&emsp;这里我们使用更加简单好用的梯度下降算法。我们需要计算出函数在每一个点上的梯度信息： $\\left(\\dfrac{\\partial \\mathcal{L}}{\\partial w}, \\dfrac{\\partial \\mathcal{L}}{\\partial b}\\right)$。我们来推导一下梯度的表达式，首先考虑 $\\dfrac{\\partial \\mathcal{L}}{\\partial w}$ ，将均方差函数展开： \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\\frac{\\displaystyle \\partial \\mathcal{L}}{\\partial w}&=\\frac{\\displaystyle \\partial \\frac{1}{n} \\sum_{i=1}^{n}\\left(w x^{(i)}+b-y^{(i)}\\right)^{2}}{\\partial w}&\\\\&=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\partial\\left(w x^{(i)}+b-y^{(i)}\\right)^{2}}{\\partial w}\\end{aligned}\n",
    "$$\n",
    "\n",
    "由于：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial g^{2}}{\\partial w}=2 \\cdot g \\cdot \\frac{\\partial g}{\\partial w}\n",
    "$$\n",
    "\n",
    "则有：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\\frac{\\partial \\mathcal{L}}{\\partial w}&=\\frac{1}{n} \\sum_{i=1}^{n} 2\\left(w x^{(i)}+b-y^{(i)}\\right) \\cdot \\frac{\\partial\\left(w x^{(i)}+b-y^{(i)}\\right)}{\\partial w} &\\\\&=\\frac{1}{n} \\sum_{i=1}^{n} 2\\left(w x^{(i)}+b-y^{(i)}\\right) \\cdot x^{(i)} &\\\\&=\\frac{2}{n} \\sum_{i=1}^{n}\\left(w x^{(i)}+b-y^{(i)}\\right) \\cdot x^{(i)}\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\\dfrac{\\partial \\mathcal{L}}{\\partial b}&=\\dfrac{\\displaystyle \\partial \\dfrac{1}{n} \\sum_{i=1}^{n}\\left(w x^{(i)}+b-y^{(i)}\\right)^{2}}{\\partial b}\\\\&=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\partial\\left(w x^{(i)}+b-y^{(i)}\\right)^{2}}{\\partial b} &\\\\&=\\frac{1}{n} \\sum_{i=1}^{n} 2\\left(w x^{(i)}+b-y^{(i)}\\right) \\cdot \\frac{\\partial\\left(w x^{(i)}+b-y^{(i)}\\right)}{\\partial b} &\\\\&=\\frac{1}{n} \\sum_{i=1}^{n} 2\\left(w x^{(i)}+b-y^{(i)}\\right) \\cdot 1 &\\\\&=\\frac{2}{n} \\sum_{i=1}^{n}\\left(w x^{(i)}+b-y^{(i)}\\right)\\end{aligned}\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;根据上面偏导数的表达式，我们只需要计算在每一个点上面的 $\\left(w x^{(i)}+b-y^{(i)}\\right)$ 和 $\\left(w x^{(i)}+b-y^{(i)}\\right)$ 值，平均后即可得到偏导数 $\\dfrac{\\partial \\mathcal{L}}{\\partial w}$ 和 $\\dfrac{\\partial \\mathcal{L}}{\\partial b}$ 。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e63ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算偏导数\n",
    "def step_gradient(b_current, w_current, points, lr) :\n",
    "    # 计算误差函数在所有点上的异数，并更新w，b\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    # 总体样本\n",
    "    M = float(len(points))\n",
    "    for i in range(0, len(points)) :\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # 偏b\n",
    "        b_gradient += (2 / M) * ((w_current * x + b_current) - y)\n",
    "        # 偏w\n",
    "        w_gradient += (2 / M) * x * ((w_current * x + b_current) - y)\n",
    "    # 根据梯度下降算法更新的 w',b',其中lr为学习率\n",
    "    new_b = b_current - (lr * b_gradient)\n",
    "    new_w = w_current - (lr * w_gradient)\n",
    "    return [new_b, new_w]\n",
    "    \n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['font.family'] = ['STKaiti']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 梯度更新\n",
    "def gradient_descent(points, starting_b, starting_w, lr, num_iterations) :\n",
    "    b = starting_b\n",
    "    w = starting_w\n",
    "    MSE = []\n",
    "    Epoch = []\n",
    "    for step in range(num_iterations) :\n",
    "        b, w = step_gradient(b, w, np.array(points), lr)\n",
    "        # 计算当前的均方误差，用于监控训练进度\n",
    "        loss = mse(b, w, points)\n",
    "        MSE.append(loss)\n",
    "        Epoch.append(step)\n",
    "        if step % 50 == 0 :\n",
    "            print(f\"iteration:{step}, loss:{loss}, w:{w}, b:{b}\")\n",
    "    plt.plot(Epoch, MSE, color='C1', label='均方差')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE function')\n",
    "    plt.legend(loc = 1)\n",
    "    plt.show()\n",
    "    return [b, w] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a02b2d",
   "metadata": {},
   "source": [
    "**4. 主函数**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee69c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0, loss:8.52075121569461, w:0.9683621336270813, b:0.018598967590321615\n",
      "iteration:50, loss:0.0005939300597845278, w:1.477514542941938, b:0.06613823978315139\n",
      "iteration:100, loss:0.00016616611251547874, w:1.4772610937560182, b:0.08026637756911292\n",
      "iteration:150, loss:0.00010824080152649426, w:1.4771678278317757, b:0.08546534407456151\n",
      "iteration:200, loss:0.00010039689211198855, w:1.4771335072140424, b:0.08737849449355252\n",
      "iteration:250, loss:9.933471542527609e-05, w:1.4771208776838989, b:0.08808250836281861\n",
      "iteration:300, loss:9.919088162325623e-05, w:1.477116230185043, b:0.08834157608859644\n",
      "iteration:350, loss:9.917140448460003e-05, w:1.4771145199673728, b:0.08843690956066241\n",
      "iteration:400, loss:9.916876700352793e-05, w:1.477113890630052, b:0.08847199100845321\n",
      "iteration:450, loss:9.916840985114966e-05, w:1.4771136590423013, b:0.08848490051392309\n",
      "iteration:500, loss:9.916836148764827e-05, w:1.4771135738210939, b:0.08848965103996947\n",
      "iteration:550, loss:9.916835493854371e-05, w:1.4771135424608248, b:0.08849139917027324\n",
      "iteration:600, loss:9.916835405170177e-05, w:1.4771135309206636, b:0.08849204245893828\n",
      "iteration:650, loss:9.916835393161082e-05, w:1.4771135266740378, b:0.08849227918059785\n",
      "iteration:700, loss:9.916835391534817e-05, w:1.4771135251113363, b:0.08849236629101521\n",
      "iteration:750, loss:9.916835391314785e-05, w:1.477113524536283, b:0.08849239834648838\n",
      "iteration:800, loss:9.916835391284828e-05, w:1.477113524324671, b:0.08849241014247554\n",
      "iteration:850, loss:9.916835391280702e-05, w:1.4771135242468005, b:0.08849241448324166\n",
      "iteration:900, loss:9.916835391280325e-05, w:1.4771135242181452, b:0.08849241608058574\n",
      "iteration:950, loss:9.916835391280336e-05, w:1.4771135242076006, b:0.08849241666838711\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss:9.916835391280157e-05, w1.4771135242037658, b0.08849241688214672\n"
     ]
    }
   ],
   "source": [
    "def solve(data) :\n",
    "    # 学习率\n",
    "    lr = 0.01\n",
    "    initial_b = 0\n",
    "    initial_w = 0\n",
    "    num_iterations = 1000\n",
    "    [b, w] = gradient_descent(data, initial_b, initial_w, lr, num_iterations)\n",
    "    loss = mse(b, w, data)\n",
    "    print(f'Final loss:{loss}, w{w}, b{b}')\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    data = get_data() \n",
    "    solve(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
